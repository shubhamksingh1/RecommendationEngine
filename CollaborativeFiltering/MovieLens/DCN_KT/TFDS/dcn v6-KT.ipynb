{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az-y_3qxH3gA"
   },
   "source": [
    "Let's first install and import the necessary packages for this colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PjfZWVEWAmxS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DqsyLA0UHeCl"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO6d-0zoHrz8"
   },
   "source": [
    "We can generate the data for this as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wU4FcpfHCZM"
   },
   "source": [
    "## Movielens latest small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Rvlem07wfwH"
   },
   "source": [
    "### Data processing\n",
    "\n",
    "The data processing procedure follows a similar procedure as the [basic ranking tutorial](https://www.tensorflow.org/recommenders/examples/basic_ranking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 5.64 MiB (download: 5.64 MiB, generated: 308.42 MiB, total: 314.06 MiB) to /home/ec2-user/tensorflow_datasets/movielens/1m-ratings/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36746368065f457c98eaede71326f0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b69721b70f4a9ab09162cd962c4122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239a3a6871e14907b4b02d1424deaa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe795e8dc474a5caaadf6c640b801ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177532d117ef4a73b2cedcfce23f9337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/1000209 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce908dadcb2f4522bd315b866d605dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling movielens-train.tfrecord...:   0%|          | 0/1000209 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /home/ec2-user/tensorflow_datasets/movielens/1m-ratings/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load('movielens/1m-ratings', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LOHyi7jKtpZ1"
   },
   "outputs": [],
   "source": [
    "# ratings = tfds.load('movielens/latest-small-ratings', split=\"train\")\n",
    "# movies = tfds.load('movielens/latest-small-movies', split=\"train\")\n",
    "\n",
    "# # Select the basic features.\n",
    "# ratings = ratings.map(lambda x: {\n",
    "#     \"movie_id\": x[\"movie_id\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "#     \"timestamp\": int(x[\"timestamp\"]),\n",
    "#     \"user_rating\": x[\"user_rating\"]\n",
    "# })\n",
    "# movies = movies.map(lambda x: {\n",
    "#     \"movie_id\": x[\"movie_id\"],\n",
    "#     \"movie_title\": x[\"movie_title\"]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uobbIPhi9Uw9"
   },
   "outputs": [],
   "source": [
    "# for x in movies.take(1).as_numpy_iterator():\n",
    "#   pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sYmOFuM78jBq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 35.0,\n",
      " 'movie_genres': array([0, 7]),\n",
      " 'movie_id': b'3107',\n",
      " 'movie_title': b'Backdraft (1991)',\n",
      " 'timestamp': 977432193,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'130',\n",
      " 'user_occupation_label': 18,\n",
      " 'user_occupation_text': b'technician/engineer',\n",
      " 'user_rating': 5.0,\n",
      " 'user_zip_code': b'50021'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = ratings.map(lambda x: {\n",
    "#     \"movie_id\": x[\"movie_id\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "#     \"user_rating\": x[\"user_rating\"],\n",
    "#     \"user_gender\": int(x[\"user_gender\"]),\n",
    "#     \"user_zip_code\": x[\"user_zip_code\"],\n",
    "#     \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "#     \"movie_title\": x[\"movie_title\"],\n",
    "#     \"timestamp\": int(x[\"timestamp\"]),\n",
    "#     \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),\n",
    "# })\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_id\": x[\"movie_id\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7Y_n3EPosR4A"
   },
   "outputs": [],
   "source": [
    "# ratings = tfds.load(\"movie_lens/100k-ratings\", split=\"train\")\n",
    "# ratings = ratings.map(lambda x: {\n",
    "#     \"movie_id\": x[\"movie_id\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "#     \"user_rating\": x[\"user_rating\"],\n",
    "#     \"user_gender\": int(x[\"user_gender\"]),\n",
    "#     \"user_zip_code\": x[\"user_zip_code\"],\n",
    "#     \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "#     \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Yb3KxrgSHiF"
   },
   "source": [
    "Next, we randomly split the data into 90% for training and 10% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800167.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000209*80/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209\n"
     ]
    }
   ],
   "source": [
    "print(ratings.cardinality().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900188 100020\n"
     ]
    }
   ],
   "source": [
    "train_size = ratings.cardinality().numpy()*90//100\n",
    "test_size = ratings.cardinality().numpy()*10//100\n",
    "\n",
    "print(train_size,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a5-l91jR_zEo"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(10_00_209, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(train_size)\n",
    "test = shuffled.skip(train_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRHGa9mESMVz"
   },
   "source": [
    "Then, we create vocabulary for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l9qhEcHq_VfI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f757a45e488> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f757a45e488>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f757a45e488> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f757a45e488>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f757a45e488> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f757a45e488>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f75549306a8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f75549306a8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f75549306a8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f75549306a8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f75549306a8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7f75549306a8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "CPU times: user 3min 20s, sys: 1min 4s, total: 4min 25s\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# feature_names = [\"movie_id\", \"user_id\", \"user_gender\", \"user_zip_code\",\n",
    "#                  \"user_occupation_text\", \"movie_title\", \"timestamp\", \"bucketized_user_age\",]\n",
    "\n",
    "feature_names = [\"movie_id\", \"user_id\"]\n",
    "\n",
    "vocabularies = {}\n",
    "\n",
    "for feature_name in feature_names:\n",
    "  vocab = ratings.batch(1000).map(lambda x: x[feature_name])\n",
    "  vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))\n",
    "#print(vocabularies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eti8kNkPSORk"
   },
   "source": [
    "### Model construction\n",
    "\n",
    "The model architecture we will be building starts with an embedding layer, which is fed into a cross network followed by a deep network. The embedding dimension is set to 32 for all the features. You could also use different embedding sizes for different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6lrDcBjiwnHU"
   },
   "outputs": [],
   "source": [
    "class DCN(tfrs.Model):\n",
    "\n",
    "  def __init__(self, use_cross_layer, deep_layer_sizes, projection_dim=None):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding_dimension = 32\n",
    "\n",
    "#     str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"movie_title\",\n",
    "#                     \"user_occupation_text\"]\n",
    "#     int_features = [\"timestamp\",\"user_gender\", \"bucketized_user_age\"]\n",
    "    \n",
    "    str_features = [\"movie_id\", \"user_id\"]\n",
    "    int_features = []\n",
    "\n",
    "    self._all_features = str_features + int_features\n",
    "    self._embeddings = {}\n",
    "\n",
    "    # Compute embeddings for string features.\n",
    "    for feature_name in str_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=vocabulary, mask_token=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "      \n",
    "    # Compute embeddings for int features.\n",
    "    for feature_name in int_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "              vocabulary=vocabulary, mask_value=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    if use_cross_layer:\n",
    "      self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "          projection_dim=projection_dim,\n",
    "          kernel_initializer=\"glorot_uniform\")\n",
    "    else:\n",
    "      self._cross_layer = None\n",
    "\n",
    "    self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\")\n",
    "      for layer_size in deep_layer_sizes]\n",
    "\n",
    "    self._logit_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError(\"RMSE\")]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # Concatenate embeddings\n",
    "    embeddings = []\n",
    "    for feature_name in self._all_features:\n",
    "      embedding_fn = self._embeddings[feature_name]\n",
    "      embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "    x = tf.concat(embeddings, axis=1)\n",
    "\n",
    "    # Build Cross Network\n",
    "    if self._cross_layer is not None:\n",
    "      x = self._cross_layer(x)\n",
    "    \n",
    "    # Build Deep Network\n",
    "    for deep_layer in self._deep_layers:\n",
    "      x = deep_layer(x)\n",
    "\n",
    "    return self._logit_layer(x)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"user_rating\")\n",
    "    scores = self(features)\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=scores,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDiRfzwVW9LH"
   },
   "source": [
    "### Model training\n",
    "We shuffle, batch and cache the training and test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qeFjmfUbgzcS"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(10_00_209).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5adSI3yOt2VQ"
   },
   "source": [
    "Let's define a function that runs a model multiple times and returns the model's RMSE mean and standard deviation out of multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gTDk3GloquHO"
   },
   "outputs": [],
   "source": [
    "def run_models(use_cross_layer, deep_layer_sizes, auto_encoder_sizes=None, projection_dim=None, num_runs=5, parallel=False, regularization=None,learning_rate=0.01):\n",
    "  models = []\n",
    "  rmses = []\n",
    "\n",
    "  for i in range(num_runs):\n",
    "    if not parallel:\n",
    "      model = DCN(use_cross_layer=use_cross_layer,\n",
    "                deep_layer_sizes=deep_layer_sizes,\n",
    "                projection_dim=projection_dim)\n",
    "    else:\n",
    "      model = DCN_parallel(deep_layer_sizes=deep_layer_sizes,auto_encoder_sizes=auto_encoder_sizes,\n",
    "                projection_dim=projection_dim, regularization=regularization)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    models.append(model)\n",
    "\n",
    "    model.fit(cached_train, epochs=epochs, verbose=False)\n",
    "    metrics = model.evaluate(cached_test, return_dict=True)\n",
    "    rmses.append(metrics[\"RMSE\"])\n",
    "\n",
    "  mean, stdv = np.average(rmses), np.std(rmses)\n",
    "\n",
    "  return {\"model\": models, \"mean\": mean, \"stdv\": stdv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRHjQ8g2h2-k"
   },
   "source": [
    "We set some hyper-parameters for the models. Note that these hyper-parameters are set globally for all the models for demonstration purpose. If you want to obtain the best performance for each model, or conduct a fair comparison among models, then we'd suggest you to fine-tune the hyper-parameters. Remember that the model architecture and optimization schemes are intertwined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zy3kWb5Dh0E7"
   },
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz3ftiQLXdC0"
   },
   "source": [
    "**DCN (stacked).** We first train a DCN model with a stacked structure, that is, the inputs are fed to a cross network followed by a deep network.\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1X8qoMtIYKJz4yBYifvfw4QpAwrjr70e_\" width=\"140\"/>\n",
    "</center>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hiuYPJWhgw3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 25s 21ms/step - RMSE: 0.9114 - loss: 0.8324 - regularization_loss: 0.0000e+00 - total_loss: 0.8324\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9329 - loss: 0.8736 - regularization_loss: 0.0000e+00 - total_loss: 0.8736\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9085 - loss: 0.8280 - regularization_loss: 0.0000e+00 - total_loss: 0.8280\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9118 - loss: 0.8336 - regularization_loss: 0.0000e+00 - total_loss: 0.8336\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9101 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284\n"
     ]
    }
   ],
   "source": [
    "dcn_result = run_models(use_cross_layer=True, deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwTn_UpDX_iO"
   },
   "source": [
    "**Low-rank DCN.** To reduce the training and serving cost, we leverage low-rank techniques to approximate the DCN weight matrices. The rank is passed in through argument `projection_dim`; a smaller `projection_dim` results in a lower cost. Note that `projection_dim` needs to be smaller than (input size)/2 to reduce the cost. In practice, we've observed using low-rank DCN with rank (input size)/4 consistently preserved the accuracy of a full-rank DCN.\n",
    "\n",
    "<div>\n",
    "<center>\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1ZZfUTNdxjGAaAuwNrweKkLJ1PGxMmiCm\" width=\"400\"/>\n",
    "</center>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NYxbHI7ZNJX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9009 - loss: 0.8139 - regularization_loss: 0.0000e+00 - total_loss: 0.8139\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9064 - loss: 0.8228 - regularization_loss: 0.0000e+00 - total_loss: 0.8228\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9007 - loss: 0.8131 - regularization_loss: 0.0000e+00 - total_loss: 0.8131\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9089 - loss: 0.8273 - regularization_loss: 0.0000e+00 - total_loss: 0.8273\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.8943 - loss: 0.8007 - regularization_loss: 0.0000e+00 - total_loss: 0.8007\n"
     ]
    }
   ],
   "source": [
    "dcn_lr_result = run_models(use_cross_layer=True,\n",
    "                           projection_dim=20,\n",
    "                           deep_layer_sizes=[192, 192])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5O5AoNOdaQ80"
   },
   "source": [
    "**DNN.** We train a same-sized DNN model as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iBPpwD4cGtXF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9001 - loss: 0.8108 - regularization_loss: 0.0000e+00 - total_loss: 0.8108\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9057 - loss: 0.8217 - regularization_loss: 0.0000e+00 - total_loss: 0.8217\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9074 - loss: 0.8254 - regularization_loss: 0.0000e+00 - total_loss: 0.8254\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9020 - loss: 0.8147 - regularization_loss: 0.0000e+00 - total_loss: 0.8147\n",
      "25/25 [==============================] - 0s 4ms/step - RMSE: 0.9004 - loss: 0.8115 - regularization_loss: 0.0000e+00 - total_loss: 0.8115\n"
     ]
    }
   ],
   "source": [
    "dnn_result = run_models(use_cross_layer=False,\n",
    "                        deep_layer_sizes=[192, 192, 192])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEmLB28lqvCe"
   },
   "source": [
    "Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6tRCrwaVIob"
   },
   "source": [
    "#### hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9wpFiQt0qvsz"
   },
   "outputs": [],
   "source": [
    "# class DCN_parallel(tfrs.Model):\n",
    "\n",
    "#   def __init__(self, deep_layer_sizes, projection_dim=None):\n",
    "#     super().__init__()\n",
    "#     self.embedding_dimension = 32\n",
    "\n",
    "#     # str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"user_occupation_text\"]\n",
    "#     # int_features = [\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "#     str_features = [\"movie_id\", \"user_id\"]\n",
    "#     int_features = [\"timestamp\"]\n",
    "\n",
    "\n",
    "#     self._all_features = str_features + int_features\n",
    "#     self._embeddings = {}\n",
    "\n",
    "#     # Compute embeddings for string features.\n",
    "#     for feature_name in str_features:\n",
    "#       vocabulary = vocabularies[feature_name]\n",
    "#       self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "#           [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "#               vocabulary=vocabulary, mask_token=None),\n",
    "#            tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "#                                      self.embedding_dimension)\n",
    "#     ])\n",
    "      \n",
    "#     # Compute embeddings for int features.\n",
    "#     for feature_name in int_features:\n",
    "#       vocabulary = vocabularies[feature_name]\n",
    "#       self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "#           [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "#               vocabulary=vocabulary, mask_value=None),\n",
    "#            tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "#                                      self.embedding_dimension)\n",
    "#     ])\n",
    "\n",
    "#     self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "#           projection_dim=projection_dim,\n",
    "#           kernel_initializer=\"glorot_uniform\",name=\"cross_layer\")\n",
    "    \n",
    "#     self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\", name=\"deep_layer\")\n",
    "#       for layer_size in deep_layer_sizes]\n",
    "\n",
    "#     self._concat_layers = tf.keras.layers.concatenate\n",
    "\n",
    "#     self._logit_layer = tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "\n",
    "#     self.task = tfrs.tasks.Ranking(\n",
    "#       loss=tf.keras.losses.MeanSquaredError(),\n",
    "#       metrics=[tf.keras.metrics.RootMeanSquaredError(\"RMSE\")]\n",
    "#     )\n",
    "\n",
    "#   def call(self, features):\n",
    "#     # Concatenate embeddings\n",
    "#     embeddings = []\n",
    "#     for feature_name in self._all_features:\n",
    "#       embedding_fn = self._embeddings[feature_name]\n",
    "#       embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "#     inp = tf.concat(embeddings, axis=1)\n",
    "\n",
    "#     print(inp)\n",
    "\n",
    "#     # Build Cross Network\n",
    "#     x = self._cross_layer(inp)\n",
    "    \n",
    "#     # Build Deep Network \n",
    "#     for i,deep_layer in enumerate(self._deep_layers):\n",
    "#       if i==0:\n",
    "#         y = deep_layer(inp)\n",
    "#       else:\n",
    "#         y = deep_layer(y)\n",
    "\n",
    "#     # Merge both network\n",
    "#     out = self._concat_layers([x,y])\n",
    "    \n",
    "#     out = self._logit_layer(out)\n",
    "#     return out\n",
    "\n",
    "#   def compute_loss(self, features, training=False):\n",
    "#     labels = features.pop(\"user_rating\")\n",
    "#     scores = self(features)\n",
    "#     return self.task(\n",
    "#         labels=labels,\n",
    "#         predictions=scores,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5YyjGJ_VM0y"
   },
   "source": [
    "#### Parallel with encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gE7MT8V3LJ0P"
   },
   "outputs": [],
   "source": [
    "# class DCN_parallel(tfrs.Model):\n",
    "\n",
    "#   def __init__(self, deep_layer_sizes, auto_encoder_sizes, projection_dim=None):\n",
    "#     super().__init__()\n",
    "#     self.embedding_dimension = 32\n",
    "\n",
    "#     # str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"user_occupation_text\"]\n",
    "#     # int_features = [\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "#     str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"movie_title\",\n",
    "#                     \"user_occupation_text\"]\n",
    "#     int_features = [\"timestamp\",\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "\n",
    "#     self._all_features = str_features + int_features\n",
    "#     self._embeddings = {}\n",
    "\n",
    "#     # Compute embeddings for string features.\n",
    "#     for feature_name in str_features:\n",
    "#       vocabulary = vocabularies[feature_name]\n",
    "#       self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "#           [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "#               vocabulary=vocabulary, mask_token=None),\n",
    "#            tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "#                                      self.embedding_dimension)\n",
    "#     ])\n",
    "      \n",
    "#     # Compute embeddings for int features.\n",
    "#     for feature_name in int_features:\n",
    "#       vocabulary = vocabularies[feature_name]\n",
    "#       self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "#           [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "#               vocabulary=vocabulary, mask_value=None),\n",
    "#            tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "#                                      self.embedding_dimension)\n",
    "#     ])\n",
    "\n",
    "#     self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "#           projection_dim=projection_dim,\n",
    "#           kernel_initializer=\"glorot_uniform\",name=\"cross_layer\")\n",
    "    \n",
    "#     self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\", name=\"deep_layer\")\n",
    "#       for layer_size in deep_layer_sizes]\n",
    "    \n",
    "#     self.auto_encoder_sizes = auto_encoder_sizes\n",
    "\n",
    "#     if self.auto_encoder_sizes is not None:\n",
    "#       self._autoencoders_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\", name=\"autoencoder_layer\")\n",
    "#       for layer_size in self.auto_encoder_sizes]\n",
    "\n",
    "#     self._concat_layers = tf.keras.layers.concatenate\n",
    "\n",
    "#     self._logit_layer = tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "\n",
    "#     self.task = tfrs.tasks.Ranking(\n",
    "#       loss=tf.keras.losses.MeanSquaredError(),\n",
    "#       metrics=[tf.keras.metrics.RootMeanSquaredError(\"RMSE\")]\n",
    "#     )\n",
    "\n",
    "#   def call(self, features):\n",
    "#     # Concatenate embeddings\n",
    "#     embeddings = []\n",
    "#     for feature_name in self._all_features:\n",
    "#       embedding_fn = self._embeddings[feature_name]\n",
    "#       embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "#     inp = tf.concat(embeddings, axis=1)\n",
    "\n",
    "#     # print(inp)\n",
    "\n",
    "#     # Build Cross Network\n",
    "#     x = self._cross_layer(inp)\n",
    "    \n",
    "#     # Build Deep Network \n",
    "#     for i,deep_layer in enumerate(self._deep_layers):\n",
    "#       if i==0:\n",
    "#         y = deep_layer(inp)\n",
    "#       else:\n",
    "#         y = deep_layer(y)\n",
    "\n",
    "\n",
    "#     #auto encoder\n",
    "#     if self.auto_encoder_sizes is not None:\n",
    "#       for i,autoencoders_layers in enumerate(self._autoencoders_layers):\n",
    "#         if i==0:\n",
    "#           z = autoencoders_layers(inp)\n",
    "#         else:\n",
    "#           z = autoencoders_layers(z)\n",
    "\n",
    "#     # Merge both network\n",
    "#     if self.auto_encoder_sizes is not None:\n",
    "#       out = self._concat_layers([x, y,z],name=\"concat_layer\")\n",
    "#     else:\n",
    "#       out = self._concat_layers([x, y],name=\"concat_layer\")\n",
    "#     # print(out)\n",
    "    \n",
    "#     out = self._logit_layer(out)\n",
    "#     return out\n",
    "\n",
    "#   def compute_loss(self, features, training=False):\n",
    "#     labels = features.pop(\"user_rating\")\n",
    "#     scores = self(features)\n",
    "#     return self.task(\n",
    "#         labels=labels,\n",
    "#         predictions=scores,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCN_parallel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, deep_layer_sizes, auto_encoder_sizes, regularization=None, projection_dim=None):\n",
    "    super().__init__()\n",
    "    self.embedding_dimension = 32\n",
    "\n",
    "    # str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"user_occupation_text\"]\n",
    "    # int_features = [\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "#     str_features = [\"movie_id\", \"user_id\", \"user_zip_code\", \"movie_title\",\n",
    "#                     \"user_occupation_text\"]\n",
    "#     int_features = [\"timestamp\",\"user_gender\", \"bucketized_user_age\"]\n",
    "\n",
    "    str_features = [\"movie_id\", \"user_id\"]\n",
    "    int_features = []\n",
    "\n",
    "\n",
    "    self._all_features = str_features + int_features\n",
    "    self._embeddings = {}\n",
    "\n",
    "    # Compute embeddings for string features.\n",
    "    for feature_name in str_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=vocabulary, mask_token=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "      \n",
    "    # Compute embeddings for int features.\n",
    "    for feature_name in int_features:\n",
    "      vocabulary = vocabularies[feature_name]\n",
    "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
    "          [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
    "              vocabulary=vocabulary, mask_value=None),\n",
    "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
    "                                     self.embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self._cross_layer = tfrs.layers.dcn.Cross(\n",
    "          projection_dim=projection_dim,\n",
    "          kernel_initializer=\"glorot_uniform\",name=\"cross_layer\")\n",
    "    \n",
    "    self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\", name=\"deep_layer\")\n",
    "      for layer_size in deep_layer_sizes]\n",
    "    \n",
    "    self.auto_encoder_sizes = auto_encoder_sizes\n",
    "\n",
    "    if self.auto_encoder_sizes is not None:\n",
    "      self._autoencoders_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\", name=\"autoencoder_layer\")\n",
    "      for layer_size in self.auto_encoder_sizes]\n",
    "\n",
    "    self._concat_layers = tf.keras.layers.concatenate\n",
    "    \n",
    "    if regularization is not None:\n",
    "        self._logit_layer = tf.keras.layers.Dense(1, name=\"output_layer\",kernel_regularizer=regularization)\n",
    "    else:\n",
    "        self._logit_layer = tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError(\"RMSE\")]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # Concatenate embeddings\n",
    "    embeddings = []\n",
    "    for feature_name in self._all_features:\n",
    "      embedding_fn = self._embeddings[feature_name]\n",
    "      embeddings.append(embedding_fn(features[feature_name]))\n",
    "\n",
    "    inp = tf.concat(embeddings, axis=1)\n",
    "\n",
    "    # print(inp)\n",
    "\n",
    "    # Build Cross Network\n",
    "    x = self._cross_layer(inp)\n",
    "    \n",
    "    # Build Deep Network \n",
    "    for i,deep_layer in enumerate(self._deep_layers):\n",
    "      if i==0:\n",
    "        y = deep_layer(inp)\n",
    "      else:\n",
    "        y = deep_layer(y)\n",
    "\n",
    "\n",
    "    #auto encoder\n",
    "    if self.auto_encoder_sizes is not None:\n",
    "      for i,autoencoders_layers in enumerate(self._autoencoders_layers):\n",
    "        if i==0:\n",
    "          z = autoencoders_layers(inp)\n",
    "        else:\n",
    "          z = autoencoders_layers(z)\n",
    "\n",
    "    # Merge both network\n",
    "    if self.auto_encoder_sizes is not None:\n",
    "      out = self._concat_layers([x,y,z],name=\"concat_layer\")\n",
    "    else:\n",
    "      out = self._concat_layers([x, y],name=\"concat_layer\")\n",
    "    # print(out)\n",
    "    \n",
    "    out = self._logit_layer(out)\n",
    "    return out\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"user_rating\")\n",
    "    scores = self(features)\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=scores,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dW4JvICAqy8B",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "110/110 [==============================] - 5s 39ms/step - RMSE: 1.4405 - loss: 2.0627 - regularization_loss: 0.0125 - total_loss: 2.0752\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 4s 37ms/step - RMSE: 0.9106 - loss: 0.8292 - regularization_loss: 0.0098 - total_loss: 0.8391\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 4s 38ms/step - RMSE: 0.8990 - loss: 0.8082 - regularization_loss: 0.0078 - total_loss: 0.8160\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 4s 38ms/step - RMSE: 0.8881 - loss: 0.7887 - regularization_loss: 0.0068 - total_loss: 0.7955\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 4s 37ms/step - RMSE: 0.8778 - loss: 0.7704 - regularization_loss: 0.0061 - total_loss: 0.7766\n",
      "Model: \"dcn_parallel_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_32 (Sequential)   (None, 32)                118624    \n",
      "_________________________________________________________________\n",
      "sequential_33 (Sequential)   (None, 32)                193312    \n",
      "_________________________________________________________________\n",
      "cross_layer (Cross)          multiple                  4160      \n",
      "_________________________________________________________________\n",
      "deep_layer (Dense)           multiple                  12480     \n",
      "_________________________________________________________________\n",
      "deep_layer (Dense)           multiple                  37056     \n",
      "_________________________________________________________________\n",
      "deep_layer (Dense)           multiple                  37056     \n",
      "_________________________________________________________________\n",
      "autoencoder_layer (Dense)    multiple                  8320      \n",
      "_________________________________________________________________\n",
      "autoencoder_layer (Dense)    multiple                  8256      \n",
      "_________________________________________________________________\n",
      "autoencoder_layer (Dense)    multiple                  2080      \n",
      "_________________________________________________________________\n",
      "autoencoder_layer (Dense)    multiple                  2112      \n",
      "_________________________________________________________________\n",
      "autoencoder_layer (Dense)    multiple                  8320      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         multiple                  385       \n",
      "_________________________________________________________________\n",
      "ranking_16 (Ranking)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 432,161\n",
      "Trainable params: 432,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tmp = DCN_parallel(deep_layer_sizes=[192, 192, 192],auto_encoder_sizes=[128,64,32,64,128],regularization=\"l2\") #l1,l2\n",
    "\n",
    "model_tmp.compile(optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "model_tmp.fit(cached_train, epochs=5, verbose=1)\n",
    "# model_tmp.evaluate(cached_test)\n",
    "model_tmp.summary()\n",
    "# tf.keras.utils.plot_model(model_tmp, \"multi_input_and_output_model.png\", show_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_tmp, \"multi_input_and_output_model.png\", show_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot\n",
    "# !pip install pydotplus\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y4X101Nht6HY"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(dcn_result['model'][0], \"multi_input_and_output_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eHNDpkPbqzbZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.9090 - loss: 0.8291 - regularization_loss: 0.0000e+00 - total_loss: 0.8291\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9084 - loss: 0.8269 - regularization_loss: 0.0000e+00 - total_loss: 0.8269\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9061 - loss: 0.8224 - regularization_loss: 0.0000e+00 - total_loss: 0.8224\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9014 - loss: 0.8140 - regularization_loss: 0.0000e+00 - total_loss: 0.8140\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9114 - loss: 0.8306 - regularization_loss: 0.0000e+00 - total_loss: 0.8306\n"
     ]
    }
   ],
   "source": [
    "dcn_parallel_result = run_models(use_cross_layer=True,\n",
    "                        deep_layer_sizes=[192,192,192],parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "n5ED8z7Sq1_Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9079 - loss: 0.8263 - regularization_loss: 0.0000e+00 - total_loss: 0.8263\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.8952 - loss: 0.8048 - regularization_loss: 0.0000e+00 - total_loss: 0.8048\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9036 - loss: 0.8176 - regularization_loss: 0.0000e+00 - total_loss: 0.8176\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9060 - loss: 0.8224 - regularization_loss: 0.0000e+00 - total_loss: 0.8224\n",
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.8960 - loss: 0.8053 - regularization_loss: 0.0000e+00 - total_loss: 0.8053\n"
     ]
    }
   ],
   "source": [
    "dcn_parallel2_result = run_models(use_cross_layer=True,\n",
    "                        deep_layer_sizes=[192,192,192],parallel=True, projection_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zPDFsaCDTy4W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.8997 - loss: 0.8100 - regularization_loss: 0.0000e+00 - total_loss: 0.8100\n",
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.8946 - loss: 0.8024 - regularization_loss: 0.0000e+00 - total_loss: 0.8024\n",
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.8977 - loss: 0.8072 - regularization_loss: 0.0000e+00 - total_loss: 0.8072\n",
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.9057 - loss: 0.8216 - regularization_loss: 0.0000e+00 - total_loss: 0.8216\n",
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.8862 - loss: 0.7863 - regularization_loss: 0.0000e+00 - total_loss: 0.7863\n"
     ]
    }
   ],
   "source": [
    "dcn_parallel3_result = run_models(use_cross_layer=True,\n",
    "                        deep_layer_sizes=[192,192,192],auto_encoder_sizes=[64,32,16,32,64] ,parallel=True, projection_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 7ms/step - RMSE: 0.8903 - loss: 0.7934 - regularization_loss: 0.0339 - total_loss: 0.8273\n",
      "25/25 [==============================] - 0s 10ms/step - RMSE: 0.8884 - loss: 0.7905 - regularization_loss: 0.0376 - total_loss: 0.8281\n",
      "25/25 [==============================] - 0s 7ms/step - RMSE: 0.8883 - loss: 0.7911 - regularization_loss: 0.0374 - total_loss: 0.8285\n",
      "25/25 [==============================] - 0s 7ms/step - RMSE: 0.8888 - loss: 0.7905 - regularization_loss: 0.0366 - total_loss: 0.8270\n",
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.8889 - loss: 0.7909 - regularization_loss: 0.0386 - total_loss: 0.8295\n"
     ]
    }
   ],
   "source": [
    "dcn_parallel4_result = run_models(use_cross_layer=True,\n",
    "                        deep_layer_sizes=[192,192,192],\n",
    "                        auto_encoder_sizes=[192, 64,32,16,32,64,192], \n",
    "                        parallel=True, \n",
    "                        regularization=\"l1\",\n",
    "                        learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': [<__main__.DCN_parallel at 0x7f7559777ef0>,\n",
       "  <__main__.DCN_parallel at 0x7f7559728518>,\n",
       "  <__main__.DCN_parallel at 0x7f755542f128>,\n",
       "  <__main__.DCN_parallel at 0x7f75550cc128>,\n",
       "  <__main__.DCN_parallel at 0x7f74bf5f0048>],\n",
       " 'mean': 0.8889471411705017,\n",
       " 'stdv': 0.0007040988627146844}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_parallel4_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBY0ljpl3_k5"
   },
   "source": [
    "We evaluate the model on test data and report the mean and standard deviation out of 5 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a1yj3pp0glEL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCN             RMSE mean: 0.9149, stdv: 0.0091\n",
      "DCN (low-rank)  RMSE mean: 0.9023, stdv: 0.0051\n",
      "DNN             RMSE mean: 0.9031, stdv: 0.0029\n",
      "DNN (parallel)  RMSE mean: 0.9073, stdv: 0.0034\n",
      "DNN (parallel2) RMSE mean: 0.9017, stdv: 0.0052\n",
      "DNN (parallel3) RMSE mean: 0.8968, stdv: 0.0064\n"
     ]
    }
   ],
   "source": [
    "print(\"DCN             RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_result[\"mean\"], dcn_result[\"stdv\"]))\n",
    "print(\"DCN (low-rank)  RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_lr_result[\"mean\"], dcn_lr_result[\"stdv\"]))\n",
    "print(\"DNN             RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dnn_result[\"mean\"], dnn_result[\"stdv\"]))\n",
    "print(\"DNN (parallel)  RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_parallel_result[\"mean\"], dcn_parallel_result[\"stdv\"]))\n",
    "print(\"DNN (parallel2) RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_parallel2_result[\"mean\"], dcn_parallel2_result[\"stdv\"]))\n",
    "\n",
    "print(\"DNN (parallel3) RMSE mean: {:.4f}, stdv: {:.4f}\".format(\n",
    "    dcn_parallel3_result[\"mean\"], dcn_parallel3_result[\"stdv\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K076UbT1nnq3"
   },
   "source": [
    "We see that DCN achieved better performance than a same-sized DNN with ReLU layers. Moreover, the low-rank DCN was able to reduce parameters while maintaining the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSF0gNLGX1Za"
   },
   "source": [
    "**More on DCN.** Besides what've been demonstrated above, there are more creative yet practically useful ways to utilize DCN [[1](https://arxiv.org/pdf/2008.13535.pdf)]. \n",
    "\n",
    "*   *DCN with a parallel structure*.  The inputs are fed in parallel to a cross network and a deep network.\n",
    "\n",
    "*   *Concatenating cross layers.* The inputs are fed in parallel to multiple cross layers to capture complementary feature crosses.\n",
    "\n",
    "<div class=\"fig figcenter fighighlight\">\n",
    "<center>\n",
    "  <img src=\"http://drive.google.com/uc?export=view&id=11RpNuj9s0OgSav9TUuGA7v7PuFLL6nVR\" hspace=40 width=\"600\" style=\"display:block;\">\n",
    "  <div class=\"figcaption\">\n",
    "  <b>Left</b>: DCN with a parallel structure; <b>Right</b>: Concatenating cross layers. \n",
    "  </div>\n",
    "  </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEi9PtCEdyma"
   },
   "source": [
    "### Model understanding\n",
    "\n",
    "The weight matrix $W$ in DCN reveals what feature crosses the model has learned to be important. Recall that in the previous toy example, the importance of interactions between the $i$-th and $j$-th features is captured by the ($i, j$)-th element of $W$.\n",
    "\n",
    "What's a bit different here is that the feature embeddings are of size 32 instead of size 1. Hence, the importance will be characterized by the $(i, j)$-th block\n",
    "$W_{i,j}$ which is of dimension 32 by 32.\n",
    "In the following, we visualize the Frobenius norm [[4](https://en.wikipedia.org/wiki/Matrix_norm)] $||W_{i,j}||_F$ of each block, and a larger norm would suggest higher importance (assuming the features' embeddings are of similar scales).\n",
    "\n",
    "Besides block norm, we could also visualize the entire matrix, or the mean/median/max value of each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "47ibaEBJxOoe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:23: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:24: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAERCAYAAAAaIjAkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAU+UlEQVR4nO3deZRedX3H8fdnwhoQgoS4ExB70IoUJRVBSqks4gHBHkCDeADliFiPelRElCprK1WPViiiqULYxAUrWEUWQUQRwQCyhooaZFNIRCRlh3z6x71DnwyTeZ557pPn3tz5vDzPcZ7l3vmOYz7zW++VbSIi2mKk7gIiIgYpoRYRrZJQi4hWSahFRKsk1CKiVRJqEdEqCbWIaJWEWkS0SkIt+iJp3bpriBhPQi0mTdI6wAWS3lF3LRFjJdRi0mw/DHwG+IikN9ddT0SnhFpMiiSVXy4CrgM+l2CLJkmoxaTYtqQ3At8ALge+D/yLpH1qLSyitFrdBUTzSXoe8Erbl5UvbQWcbPtMSV8H9gSOkfSk7fPrqjMC0lKLLsru5k7AXZLW63hrTwDbTwNXAvcAn5U0q6OLGiuZpDRMxkioxYRcXHDvm8ADwPHl+NnnAEuaX35sNvBr4M2273cu0jcUkp4PfEbSS+uupUkSatFV2Rp7kqI1thOwC7AfsJGk84GzgB/Z/p/6qpyS/gS8EPigpE3rLqYplD+q0Y0klRMEzwEOBl4KnG/70rJLur7tu0Y/V2+1U4Ok1Ww/JWlb4CTgj8Chtu+uubTapaUWXZWBJttLgVOB3wBzJe1t+yHbd41+rtZCpwhJI2WgvRE4ATiRosV2vKTZ9VZXv4RaTGh00L8j2B4C5gMLgVvrrG2qkbSppM1sL5M0DXgr8B3bZwBzgDWAkyVtXGuhNUuoxTNGA0zSOpJWh2fCbKTj69FgO8n2ws7jYqV7PbChpLXKcc5bgA0krWd7GfBe4HXAYZLWrrPQOiXUAlhu3Gx34DvAiZKOBij/wVB+7XI850lJa0qanm7ncNg+C/gdcLWkVwA/pmihbSPpucAs4ALgbNuP1ldpvRJqU9yY7uXfAccAHwYWA3t1/sVXYVo5njMDOA2YWUPZU5btJcC3KMY27wNOAQ6i+F2cB5xl++q66muCzH5OYeVOgW2B75XjNG8CHgOmA58E3mb795JeYXthOUC9TNL6wHeBY2z/pL6fYOqS9FFgX2Bv4F7gZcBqtm+ptbAGyGrkqW0OxbjMDElPUPz/4UzgTmAX20sl7QTsK+njtv9cBtp/A5+w/bPaKp8iVrRMxvZnJT0NXAK81faNw6+umRJqU5jtH5TrzE4AbrD9lbIL+kZgDUl7Ap8GDi8DbRrwMRJow7Q+8OB4b9j+fPk7WW+896eqdD+nMElzgN8DbwB2AK4BzgGOBzYD1qTYuP7DjmPWt/2XGsqdciTtTPFHZG9g6UQTMp1jo0Mqr7HSUpva/glY2/Z+5bKN1wNP2z4coJzZfKT8esT2sgTacJSzm++jaCU/NN6ymXLS5unR3QXDr7KZMvs5hYzzD+PDwFJJr7R9DkVLbUdJh5RXf3hs9IOdyzpi5ZI0Hdgd2AbYBJ7dAusItBnAheWSjiAttSmlXLbxD8DqwPW2F0taCuwD3GL7jLLFdk3+8g9XxzrBtYFHgS8DawN7SLrf9pUdn+0MtG8Bx9t+oJbCGyhjalOMpLdRbEq/neJy3BcAF1Fshv55nbVNdZL2At4BrAV8heJ3tAfF+OY3bF/R8dkNKALtWNs/raHcxkr3s+U6tj5tXV7RYQGwG8XSjUOBwyhabjuMboeK4ZO0HXAExTjaX4CPlJdy+g7FJZ8OKFtmlL+nfwM+nUB7trTUpoDyag4nUdxPYC5wtO155f7OPSg2Rp9t+/s1ljmlSZoLLAOeBj4C7G97kYr7q65JcXmn33V8/jnlVVNijIRai5V/0Z9D8df+87YvkPQa4NvAv9r+2pjP53poQ9IxhrZpGV57UsxGTwcOLF/bl2LXwAG2H5vwhPGMdDdaqGOWc3VgKXA18Gg5wHwd8EFg99ErcYxKoA1PGWhvAk5XcdXayylmmxcCa0naBfgUcHoCbXIy+9lC5T+YtwDvBn5Lsf5sGsV42lLgEYpuTkKsJpK2Bk6m2F+7qHzt7RS7Ow4HNgQ+Vrau04KehIRai3R0aWZQXLnhbIrg2p5iUmB6ua1me+CTWbZRDxVXp90GmAfcI+mDwIEUrbQDR6+CYvtBSAt6shJqLVIG2mspNqpfa/vrAJIeBo4qPzYf+LrtK9MCGD4Vd4AaHTubS3FRx8sobmRzMrAj8CPgoZpKXOUl1Fqgo4X2OuCrFPs5Z0n6GfAz298rN64fSbEZ/X8hLYBhGfPH437gNoru5ZeA/7R9t6TNKS7y+AfIDo4qMvvZEpK2AY6lWN90s6TjgBnAucDPyyvVvsj2PXXWOVWV69A2tX12OQTwNuBvKe7z8DDwUYrr051XX5XtkNnP9lif4p6cu5bPj6W4AfGBFGNoJNBqtQFwnKS5Lu4v8C2KSZsDgFcDH7J93ngb12NyEmotYftiikvUHCzp7bafBI6juB/k/bUWF9j+AcVugY+Xv5+nKMbO7gW+bPvy8nPpOlWUMbUWsX2+pCcpWgRr2J4PfKLmsqJk+4eSDJxRdkd3Bd5j+7c1l9YqGVNroXJ1+gnAzsB9ZXcnGkLSFsB2wK25gvDgJdRaStJGthfXXUfEsCXUIqJVMlEQEa2SUIuIVkmoRUSrJNRWYZIOqbuGmFh+R8OXUFu15R9M8+V3NGQJtYholSm1pGPDmTM9e/YmdZcxMEsWL2bmRhvVXcZA3XhHu+70tuzxhxhZc726yxiYZQ8vZtljS5/Znzptvdn2U492Pc6PLr7I9m4rtbjSlNomNXv2JvzkymvqLiMmsPG7z6m7hJjA0gs+udxzP/UYa758btfjHrv+pJkrq6axplSoRcSACWjYhUUSahFRTcNuF5tQi4hq0lKLiPZQWmoR0SICRqbVXcVyEmoRUYHS/YyIlkn3MyJaJS21iGgNKWNqEdEy6X5GRHtkSUdEtM1IxtQioi1EWmoR0SaZKIiItmnYko5mtRsjYtWjke6PbqeQTpV0v6Sbx3nvMEmW1NM12RJqEdE/qbdHd/OBZ10ZV9JLgF2AO3stKaEWEdWMTOv+6ML2FcB413L/AnA40PN9BzKmFhEV9LxObaakBR3P59meN+GZpT2Be2zfoEmM2yXUIqKa3gJnie05vZ9S04EjgV0nW066nxHRv9F1ahUnCsaxGbApcIOkO4AXA9dJen63A9NSi4gKVs42Kds3AbOe+S5FsM2xvaTbsWmpRUQ1A5gokHQOcBWwuaS7JR3cbzlpqUVENQNYfGt7vy7vb9LruRJqEdE/5SodEdE2DdsmlVCLiL4JGBlJSy0i2kLlo0ESahFRgZjMav9hSKhFRCUJtYholYRaRLSHQLlHQUS0hTKmFhFtk1CLiFZJqEVEe2RMLSLaJi21iGiNTBREROsk1CKiXZqVaQm1iKhAuUpHRLRMup8R0RqZKIiI9mlWpiXUIqKCjKlFRNuk+xkR7dKsTEuoRUQ1TWup1dIZlnSopAMGdZykTSTdPJjqIqJXkhgZGen6GKZaWmq2vzzM4yJi5VnlWmplK+g2SV+VdLOksyXtLOlKSbdLeq2k50o6T9KNkn4haUtJI5LukDSj41y/kfQ8SUdLOqx8bTNJF0q6VtJPJb18glo6j9ta0g2SrgLeN8Exh0haIGnBksWLJ/O/TUT0Qj08hqjXduHLgC8CWwIvB94ObA8cBnwCOAa43vaW5fMzbC8Dzgf+EUDSNsAdtu8bc+55wPttb12e70s91nQa8AHb2070IdvzbM+xPWfmRhv1eOqI6JWkro9h6rX7ucj2TQCSbgEutW1JNwGbALOBvQFsXyZpQ0nrA98EPkURQHPL58+QtC6wHfDtjh98zW7FlOeeYfsn5UtnAm/q8WeJiEFR87qfvYba4x1fL+t4vqw8x1PjHGPgKuBlkjYC3gIcP+YzI8CDtrfqsY5RKs8fETUSYqRhV74d1LTEFcD+AJJ2BJbYfsi2ge8CnwcW2v5T50G2HwIWSdq3PFaS/qbbN7P9IPAXSduXL+0/oJ8jIiZJ6v4YpkHNfh4NnCbpRuAR4MCO974J/BI4aAXH7g+cIumfgdWBbwA39PA93wmcKukR4KL+yo6Iqla57qftO4AtOp4ftIL39lrB8QsYM/9h++iOrxcBu/VS7JjjrgU6W3VHj/18RKxkNbTEusmOgojom4Bp05qVao0MNUlHAvuOefnbtv+ljnoiYsVWue5nHcrwSoBFNN2Aup+STgX2AO63vUX52meBNwNPAL8F3llOEk6oWRdCiohVihjY4tv5PHts/RJgi3JR/6+Bj/dyooRaRFTQPdB6CTXbVwAPjHntYtuja2B/Aby4l4oa2f2MiFXHkBbfvosxO5JWJKEWEf3rfUxtpqQFHc/n2Z7X07coJg6fAs7u5fMJtYjo2+iYWg+W2J4z6fNLB1JMIOxU7lDqKqEWEZWsrBUdknYDPgb8ve1Hej0uoRYRlQxiTE3SOcCOFN3Uu4GjKGY71wQuKVuDv7B9aLdzJdQion8DuvSQ7f3Geflr/ZwroRYRfSvG1OquYnkJtYioYPhXtu0moRYRlTQs0xJqEVGBhrb4tmcJtYjo2yTWqQ1NQi0iKkmoRUSrNCzTEmoRUUHG1CKiTZQlHRHRNg3LtIRaRFQz0rBUS6hFRCUNy7SEWkT0T4JpmSiIiDbJREFEtErDMi2hFhH9E8WyjiZJqEVE/6SMqUVEu6T7GRGtIbJOLSJapmGZllCLiGqypCMiWiOLbyOidZoVaQm1iKgo3c+IaI1i9rPuKpaXUIuI/km58m1EtEu6nxHRGul+RkTrpKUWEa3SrEhLqEVEBVl8GxGtk+5nRLRKwzItoRYR/RPKpYfq9KuFdzJr2w/UXUZM4M+//I+6S4gJvH6bLyz/gmjc4tuRuguIiFXbSA+PbiSdKul+STd3vPZcSZdIur387w16rScioi+imCjo9ujBfGC3Ma8dAVxq+6+AS8vnXSXUIqKSEXV/dGP7CuCBMS/vBZxefn068JZe6plSY2oRMVgreZ3a82z/AcD2HyTN6uWghFpEVNJjps2UtKDj+Tzb81ZGPQm1iKikxxUdS2zPmeSp75P0grKV9gLg/l4OyphaRPRt9BZ53R59+h5wYPn1gcD5vRyUUIuISga0pOMc4Cpgc0l3SzoYOAHYRdLtwC7l867S/YyIvkkayESB7f1W8NZOkz1XQi0iKmnYLqmEWkRU07BdUgm1iOjf6ERBkyTUIqJ/gmkNm25MqEVEJWrYBb0TahHRt9xNKiJaJ6EWEa2SexRERGsoEwUR0TZZ0hERrZGJgohonYY11BJqEdE/IaY1LNUSahHRvx7vQTBMCbWIqCQTBRHRGsUt8uquYnkJtYioJC21iGgNAdOalWkJtYioQNkmFREt06xIS6hFRAW58m1EtE7WqUVEiyhjahHRHqJ5d0RPqEVEJWmpRUSrNCvSEmoRUYFErtIREe2S7mdEtEqzIi2hFhEVNayhllCLiP4VG9qblWoJtYioQKhhHdCEWkRU0rCGWkItIvpX7ChoVqol1CKif0pLLSJapmmXHmraXtSIWIWM3qG926Onc0kfknSLpJslnSNprX5qSqhFRCXq4T9dzyG9CPgAMMf2FsA0YG4/9aT7GRGVDLD3uRqwtqQngenAvf2eJCKiL5NYfDtT0oKO5/Nszxt9YvseSZ8D7gQeBS62fXE/Na1S3U9JL5R07greu1zSnGHXFDG19dL5FMAS23M6HvOWO4u0AbAXsCnwQmAdSe/op6JGhpqkcVuQtu+1vc+w64mIFSiXdHR79GBnYJHtxbafBP4L2K6fkgbS/ZS0CfD9coAPSYcB6wIPAIcCTwG32p4raR3gJOBV5fc/2vb5kg4CdgfWAtYB3jDR95G0NnAa8NfAQmDtQfwsETE5AxpSuxN4naTpFN3PnYAFEx8yvpU9pnYEsKntxyXNKF87ErjM9rvK166R9KPyvW2BLW0/0MO53ws8YntLSVsC1433IUmHAIcAsPq6ff8gEfFsg7pFnu2ry6Gl6ygaQdcD8yY+anwrO9RuBM6WdB5wXvnarsCeZWsOipbZxuXXl/QYaAA7ACcC2L5R0o3jfajsu88DGJk+y5P9ASJiYoOa/bR9FHBU1fMMakztqTHnGl00tztwMrA1cG05ViZgb9tblY+NbS8sP//wJL9vQiqiZoNYpzZIgwq1+4BZkjaUtCawR3nul9j+MXA4MINinO0i4P0qrwEs6dV9fs8rgP3Lc2wBbFnpJ4iIvgxoomBgBtL9tP2kpGOBq4FFwG0UK4LPkrQ+RevsC7YflHQc8O/AjWWw3UERgpN1CnBa2e38FXBN1Z8jIiavWTs/BzimZvtEyjGuLp97FHjPOK/PB+Z3OfYOYIuO8/S1jSIiBkPkxisR0Sa59FBvJL0KOHPMy4/b3qaOeiJixRqWac0MNds3AVvVXUdE9KBhqdbIUIuIVYUad5HIhFpE9E00rqGWUIuIihqWagm1iKgk9/2MiFZp2JBaQi0iKsg6tYhom3Q/I6I1im1SdVexvIRaRFTSsExLqEVENdnQHhGt0rBMS6hFRDUNy7SEWkRU1LBUS6hFRN+KvZ/NSrWEWkT0TzDSrExLqEVERQm1iGiP4d8Cr5uEWkRUkiUdEdEa2SYVEa2T7mdEtEpaahHRKg3LtIRaRFSQi0RGRJsUEwXNSrWEWkRU0qxIS6hFREUNa6gl1CKimizpiIhWaVpLbaTuAiJi1SX19ujtXJoh6VxJt0laKGnbfmpKSy0iKhlg9/OLwIW295G0BjC9n5Mk1CKimgFkmqT1gB2AgwBsPwE80c+50v2MiErUw6MHLwUWA6dJul7SVyWt0089CbWIqECMqPsDmClpQcfjkDEnWg14DXCK7VcDDwNH9FNRup8R0bdJXHpoie05E7x/N3C37avL5+fSZ6ilpRYRtbP9R+AuSZuXL+0E3NrPudJSi4hKBrhO7f3A2eXM5++Ad/ZzkoRaRPRPjI6ZVWb7V8BEXdSeJNQiom+TmN0cmoRaRFTTsFRLqEVEJdnQHhGt0rQN7Qm1iKgkoRYRrdK07qds113D0EhaDPy+7joGaCawpO4iYkJt+x3Ntr3R6BNJF1L8jN0ssb3byivr/02pUGsbSQu6bD2JmuV3NHzZJhURrZJQi4hWSait2ubVXUB0ld/RkGVMLSJaJS21iGiVhFpEtEpCLSJaJaEWEa2SUIuIVvk/Tv/iDMfe7jgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = dcn_result[\"model\"][4]\n",
    "mat = model._cross_layer._dense.kernel\n",
    "features = model._all_features\n",
    "\n",
    "block_norm = np.ones([len(features), len(features)])\n",
    "\n",
    "dim = model.embedding_dimension\n",
    "\n",
    "# Compute the norms of the blocks.\n",
    "for i in range(len(features)):\n",
    "  for j in range(len(features)):\n",
    "    block = mat[i * dim:(i + 1) * dim,\n",
    "                j * dim:(j + 1) * dim]\n",
    "    block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "cax.tick_params(labelsize=10) \n",
    "_ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
    "_ = ax.set_yticklabels([\"\"] + features, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZKyHk-L4Kg8"
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "r-nB7npr4KXT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 6ms/step - RMSE: 0.9101 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9101490378379822, 0.8290325403213501, 0, 0.8290325403213501]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NlBVsoLl4sW9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step - RMSE: 0.9101 - loss: 0.8284 - regularization_loss: 0.0000e+00 - total_loss: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.9101490378379822,\n",
       " 'loss': 0.8290325403213501,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.8290325403213501}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_result['model'][-1].evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "29Uv7wqV4KQr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test data.. \n",
      "#0 DCN Base \t\t RMSE: 0.91\n",
      "#1 DCN with LR \t\t RMSE: 0.89\n",
      "#2 DNN  \t\t RMSE: 0.90\n",
      "#3 Parallel \t\t RMSE: 0.91\n",
      "#4 Parallel 2 \t\t RMSE: 0.90\n",
      "#5 Parallel 3 \t\t RMSE: 0.89\n"
     ]
    }
   ],
   "source": [
    "my_list = [dcn_result, dcn_lr_result, dnn_result, dcn_parallel_result,dcn_parallel2_result, dcn_parallel3_result]\n",
    "my_model_name = [\"DCN Base\", \"DCN with LR\", \"DNN \", \"Parallel\", \"Parallel 2\", \"Parallel 3\"]\n",
    "print('Testing on test data.. ')\n",
    "for i,name in enumerate(my_list):\n",
    "  print(\"#\"+str(i)+ \" \" +str(my_model_name[i]), end=\" \")\n",
    "  result = name['model'][-1].evaluate(cached_test,return_dict=True, verbose=False)\n",
    "  print('\\t\\t RMSE: {:.2f}'.format(result['RMSE']))\n",
    "\n",
    "  # print(\"DNN (parallel2) RMSE mean: {:.4f}, stdv: {:.4f}\".format(dcn_parallel2_result[\"mean\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rylOs9Te-s1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.919224 ],\n",
       "       [3.7159245],\n",
       "       [3.7252152],\n",
       "       ...,\n",
       "       [3.468406 ],\n",
       "       [3.5185535],\n",
       "       [2.3079493]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tmp.predict(cached_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHztTy526Atd"
   },
   "outputs": [],
   "source": [
    "#predict function created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 100\n",
    "# # dictionary of arrays:\n",
    "# # metadata = {\n",
    "# #     'bucketized_user_age': \"1\",\n",
    "# #     'movie_id': '1416',\n",
    "# #     'movie_title': 'Thunderball (1965)',\n",
    "# #     'timestamp': \"975658116\",\n",
    "# #     'user_gender': \"1\",\n",
    "# #     'user_id': '1285',\n",
    "# #     'user_occupation_text': 'college/grad student',\n",
    "# #     'user_rating': \"4.0\",\n",
    "# #     'user_zip_code': '98125'\n",
    "# #     }\n",
    "\n",
    "# metadata = {\n",
    "#     'bucketized_user_age': \"1\",\n",
    "#     'movie_id': '1416',\n",
    "#     'movie_title': 'Thunderball (1965)',\n",
    "#     'timestamp': \"975658116\",\n",
    "#     'user_gender': \"1\",\n",
    "#     'user_id': '1285',\n",
    "#     'user_occupation_text': 'college/grad student',\n",
    "#     'user_rating': \"4.0\",\n",
    "#     'user_zip_code': '98125'\n",
    "#     }\n",
    "# num_samples = N\n",
    "\n",
    "# def meta_dict_gen():\n",
    "#     for i in range(num_samples):\n",
    "#         ls = {}\n",
    "#         for key, val in metadata.items():\n",
    "#             ls[key] = val[i]\n",
    "#         yield ls\n",
    "\n",
    "# dataset = tf.data.Dataset.from_generator(\n",
    "#     meta_dict_gen,\n",
    "#     output_types={\"movie_id\": tf.string, \"user_id\": tf.string, \"user_rating\": tf.float32, \"user_gender\": tf.int32, \"user_zip_code\": tf.string, \"user_occupation_text\": tf.string, \"movie_title\": tf.string, \"timestamp\": tf.int32, \"bucketized_user_age\": tf.int32},\n",
    "#     output_shapes={\"movie_id\": (), \"user_id\": (), \"user_rating\": (), \"user_gender\": (), \"user_zip_code\": (), \"user_occupation_text\": (), \"movie_title\": (), \"timestamp\": (), \"bucketized_user_age\": ()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movies.csv', 'ratings.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"KT_DCN/ml-1m/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       5\n",
       "1        1       661       3\n",
       "2        1       914       3\n",
       "3        1      3408       4\n",
       "4        1      2355       5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_rating = pd.read_csv(\"KT_DCN/ml-1m/ratings.csv\", usecols=[\"user_id\",\"movie_id\",\"rating\"])\n",
    "my_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     6040\n",
       "movie_id    3706\n",
       "rating         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rating.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(my_rating.groupby(\"userId\").groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3943</th>\n",
       "      <th>3944</th>\n",
       "      <th>3945</th>\n",
       "      <th>3946</th>\n",
       "      <th>3947</th>\n",
       "      <th>3948</th>\n",
       "      <th>3949</th>\n",
       "      <th>3950</th>\n",
       "      <th>3951</th>\n",
       "      <th>3952</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                               ...   \n",
       "1          5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5          0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0  ...   \n",
       "6          4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7          0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0  ...   \n",
       "8          4.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "9          5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "10         5.0   5.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "movie_id  3943  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n",
       "user_id                                                               \n",
       "1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "8          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "9          0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0  \n",
       "10         0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[10 rows x 3706 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_matrix = my_rating.reset_index()[[\"user_id\", \"movie_id\", \"rating\"]].pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\")\n",
    "pref_matrix = pref_matrix.fillna(0)\n",
    "pref_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_dict = pref_matrix.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = list(pref_matrix.index)\n",
    "movieId = list(pref_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(userId), len(movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "final_movie_id = []\n",
    "final_user_id = []\n",
    "final_rating = []\n",
    "for i in my_test_dict.items():\n",
    "    \n",
    "    tmp = [i[0] for j in range(len(userId))]\n",
    "#     print(\"movie id \"+str(tmp))\n",
    "    final_movie_id.extend(tmp)\n",
    "    \n",
    "#     print(\"user id \"+str(list(i[1].keys())))\n",
    "    final_user_id.extend(list(i[1].keys()))\n",
    "\n",
    "#     print(\"ratings id \"+str(list(i[1].values())))\n",
    "    final_rating.extend(list(i[1].values()))\n",
    "#     count+=1\n",
    "#     if count>5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22384240, 22384240, 22384240)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_movie_id), len(final_user_id), len(final_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_id = [str(i) for i in final_movie_id]\n",
    "final_user_id = [str(i) for i in final_user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(final_movie_id)\n",
    "# dictionary of arrays:\n",
    "# metadata = {\n",
    "#     'bucketized_user_age': \"1\",\n",
    "#     'movie_id': '1416',\n",
    "#     'movie_title': 'Thunderball (1965)',\n",
    "#     'timestamp': \"975658116\",\n",
    "#     'user_gender': \"1\",\n",
    "#     'user_id': '1285',\n",
    "#     'user_occupation_text': 'college/grad student',\n",
    "#     'user_rating': \"4.0\",\n",
    "#     'user_zip_code': '98125'\n",
    "#     }\n",
    "\n",
    "metadata = {\n",
    "    'movie_id': final_movie_id,\n",
    "    'user_id': final_user_id,\n",
    "    'user_rating': final_rating,\n",
    "    }\n",
    "num_samples = N\n",
    "\n",
    "def meta_dict_gen():\n",
    "    for i in range(num_samples):\n",
    "        ls = {}\n",
    "        for key, val in metadata.items():\n",
    "            ls[key] = val[i]\n",
    "        yield ls\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    meta_dict_gen,\n",
    "    output_types={\"movie_id\": tf.string, \"user_id\": tf.string, \"user_rating\": tf.float32},\n",
    "    output_shapes={\"movie_id\": (), \"user_id\": (), \"user_rating\": ()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map(lambda x: {\n",
    "#     \"movie_id\": x[\"movie_id\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "#     \"user_rating\": x[\"user_rating\"],\n",
    "#     \"user_gender\": int(x[\"user_gender\"]),\n",
    "#     \"user_zip_code\": x[\"user_zip_code\"],\n",
    "#     \"user_occupation_text\": x[\"user_occupation_text\"],\n",
    "#     \"movie_title\": x[\"movie_title\"],\n",
    "#     \"timestamp\": int(x[\"timestamp\"]),\n",
    "#     \"bucketized_user_age\": int(x[\"bucketized_user_age\"]),\n",
    "# })\n",
    "\n",
    "dataset = dataset.map(lambda x: {\n",
    "    \"movie_id\": x[\"movie_id\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_id': array([b'1'], dtype=object),\n",
      " 'user_id': array([b'1'], dtype=object),\n",
      " 'user_rating': array([5.], dtype=float32)}\n",
      "{'movie_id': array([b'1'], dtype=object),\n",
      " 'user_id': array([b'2'], dtype=object),\n",
      " 'user_rating': array([0.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for x in dataset.batch(1).take(2).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485.17724609375"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6083286/4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_test_dataset = dataset.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5465/5465 [==============================] - 3440s 629ms/step\n",
      "CPU times: user 1h 3min 31s, sys: 9min 16s, total: 1h 12min 48s\n",
      "Wall time: 57min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = model_tmp.predict(cached_test_dataset,verbose=True)\n",
    "preds = preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predicted_rating = [i for i in preds.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22384240"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.295855, 4.141455, 4.532125, 4.0342045, 3.2023442]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predicted_rating[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data = list(zip(final_user_id,final_movie_id,final_rating,final_predicted_rating)),columns=['UserId','movieId','rating','predicted_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.295855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.532125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.202344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId  rating  predicted_rating\n",
       "0      1       1     5.0          4.295855\n",
       "1      2       1     0.0          4.141455\n",
       "2      3       1     0.0          4.532125\n",
       "3      4       1     0.0          4.034204\n",
       "4      5       1     0.0          3.202344"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.295855</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.141455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.532125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034204</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.202344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId  rating  predicted_rating  final_score\n",
       "0      1       1     5.0          4.295855          5.0\n",
       "1      2       1     0.0          4.141455          0.0\n",
       "2      3       1     0.0          4.532125          0.0\n",
       "3      4       1     0.0          4.034204          0.0\n",
       "4      5       1     0.0          3.202344          0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['final_score'] = result_df['rating']\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2_df = result_df[result_df[\"final_score\"]==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dcn v6-KT.ipynb', '.ipynb_checkpoints', 'ml-1m', 'TFDS']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"KT_DCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2_df.to_pickle(\"KT_DCN/TFDS/DCN_Result2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_pickle(\"KT_DCN/TFDS/DCN_Result.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20336680</th>\n",
       "      <td>1</td>\n",
       "      <td>3607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.911602</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17848200</th>\n",
       "      <td>1</td>\n",
       "      <td>3172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.886096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370320</th>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.883095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180400</th>\n",
       "      <td>1</td>\n",
       "      <td>3233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.684411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790440</th>\n",
       "      <td>1</td>\n",
       "      <td>3338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.634354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId movieId  rating  predicted_rating  final_score\n",
       "20336680      1    3607     0.0          4.911602          0.0\n",
       "17848200      1    3172     0.0          4.886096          0.0\n",
       "3370320       1     572     0.0          4.883095          0.0\n",
       "18180400      1    3233     0.0          4.684411          0.0\n",
       "18790440      1    3338     0.0          4.634354          0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = result_df[result_df['UserId']==\"1\"].sort_values(by='predicted_rating', ascending=False)[:10]\n",
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('KT_DCN/ml-1m/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                               movie                         genre\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.rename(columns = {\"movie_id\": \"movieId\",\"movie\":\"title\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title                         genre\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movieId                               title\n",
       "0       1                    Toy Story (1995)\n",
       "1       2                      Jumanji (1995)\n",
       "2       3             Grumpier Old Men (1995)\n",
       "3       4            Waiting to Exhale (1995)\n",
       "4       5  Father of the Bride Part II (1995)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp = temp[['movieId', 'title']]\n",
    "temp[\"movieId\"] = temp[\"movieId\"].astype(str)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "finally_final = final2_df.merge(temp,on=\"movieId\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11572753</th>\n",
       "      <td>4</td>\n",
       "      <td>2197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.006701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Firelight (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17826455</th>\n",
       "      <td>4</td>\n",
       "      <td>3323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.976559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chain of Fools (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282527</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.946044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lamerica (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250558</th>\n",
       "      <td>4</td>\n",
       "      <td>578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.883179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hour of the Pig, The (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720870</th>\n",
       "      <td>4</td>\n",
       "      <td>668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.863266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pather Panchali (1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295014</th>\n",
       "      <td>4</td>\n",
       "      <td>787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.836448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gate of Heavenly Peace, The (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637306</th>\n",
       "      <td>4</td>\n",
       "      <td>858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.834882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517337</th>\n",
       "      <td>4</td>\n",
       "      <td>2905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.827373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sanjuro (1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19525807</th>\n",
       "      <td>4</td>\n",
       "      <td>3629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.805963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gold Rush, The (1925)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978838</th>\n",
       "      <td>4</td>\n",
       "      <td>923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.796127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId movieId  rating  predicted_rating  final_score  \\\n",
       "11572753      4    2197     0.0          5.006701          0.0   \n",
       "17826455      4    3323     0.0          4.976559          0.0   \n",
       "282527        4      53     0.0          4.946044          0.0   \n",
       "3250558       4     578     0.0          4.883179          0.0   \n",
       "3720870       4     668     0.0          4.863266          0.0   \n",
       "4295014       4     787     0.0          4.836448          0.0   \n",
       "4637306       4     858     0.0          4.834882          0.0   \n",
       "15517337      4    2905     0.0          4.827373          0.0   \n",
       "19525807      4    3629     0.0          4.805963          0.0   \n",
       "4978838       4     923     0.0          4.796127          0.0   \n",
       "\n",
       "                                       title  \n",
       "11572753                    Firelight (1997)  \n",
       "17826455               Chain of Fools (2000)  \n",
       "282527                       Lamerica (1994)  \n",
       "3250558          Hour of the Pig, The (1993)  \n",
       "3720870               Pather Panchali (1955)  \n",
       "4295014   Gate of Heavenly Peace, The (1995)  \n",
       "4637306                Godfather, The (1972)  \n",
       "15517337                      Sanjuro (1962)  \n",
       "19525807               Gold Rush, The (1925)  \n",
       "4978838                  Citizen Kane (1941)  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finally_final[finally_final['UserId']==\"4\"].sort_values(by='predicted_rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.141455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.532125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.202344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.160647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId  rating  predicted_rating  final_score             title\n",
       "0      2       1     0.0          4.141455          0.0  Toy Story (1995)\n",
       "1      3       1     0.0          4.532125          0.0  Toy Story (1995)\n",
       "2      4       1     0.0          4.034204          0.0  Toy Story (1995)\n",
       "3      5       1     0.0          3.202344          0.0  Toy Story (1995)\n",
       "4      7       1     0.0          4.160647          0.0  Toy Story (1995)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finally_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "finally_final.to_pickle(\"KT_DCN/TFDS/DCN_recommendation_final_result.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment with pickle size vs load time tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"KT_DCN/TFDS/DCN_recommendation_final_result.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.141455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.532125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.034204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.202344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.160647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId  rating  predicted_rating  final_score             title\n",
       "0      2       1     0.0          4.141455          0.0  Toy Story (1995)\n",
       "1      3       1     0.0          4.532125          0.0  Toy Story (1995)\n",
       "2      4       1     0.0          4.034204          0.0  Toy Story (1995)\n",
       "3      5       1     0.0          3.202344          0.0  Toy Story (1995)\n",
       "4      7       1     0.0          4.160647          0.0  Toy Story (1995)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>final_score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21384026</th>\n",
       "      <td>6036</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.472005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384027</th>\n",
       "      <td>6037</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.456575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384028</th>\n",
       "      <td>6038</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.716425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384029</th>\n",
       "      <td>6039</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.544908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384030</th>\n",
       "      <td>6040</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.920799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId movieId  rating  predicted_rating  final_score  \\\n",
       "21384026   6036    3952     0.0          3.472005          0.0   \n",
       "21384027   6037    3952     0.0          3.456575          0.0   \n",
       "21384028   6038    3952     0.0          3.716425          0.0   \n",
       "21384029   6039    3952     0.0          3.544908          0.0   \n",
       "21384030   6040    3952     0.0          2.920799          0.0   \n",
       "\n",
       "                          title  \n",
       "21384026  Contender, The (2000)  \n",
       "21384027  Contender, The (2000)  \n",
       "21384028  Contender, The (2000)  \n",
       "21384029  Contender, The (2000)  \n",
       "21384030  Contender, The (2000)  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21384031, 6)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.final_score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df[['UserId','movieId','title','predicted_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21384031, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.532125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>3.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.160647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId             title  predicted_rating\n",
       "0      2       1  Toy Story (1995)          4.141455\n",
       "1      3       1  Toy Story (1995)          4.532125\n",
       "2      4       1  Toy Story (1995)          4.034204\n",
       "3      5       1  Toy Story (1995)          3.202344\n",
       "4      7       1  Toy Story (1995)          4.160647"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5983277</th>\n",
       "      <td>667</td>\n",
       "      <td>163949</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>3.641303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983278</th>\n",
       "      <td>668</td>\n",
       "      <td>163949</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>3.451962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983279</th>\n",
       "      <td>669</td>\n",
       "      <td>163949</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>3.903868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983280</th>\n",
       "      <td>670</td>\n",
       "      <td>163949</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>2.308453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983281</th>\n",
       "      <td>671</td>\n",
       "      <td>163949</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>3.856942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserId movieId                                              title  \\\n",
       "5983277    667  163949  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "5983278    668  163949  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "5983279    669  163949  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "5983280    670  163949  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "5983281    671  163949  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "\n",
       "         predicted_rating  \n",
       "5983277          3.641303  \n",
       "5983278          3.451962  \n",
       "5983279          3.903868  \n",
       "5983280          2.308453  \n",
       "5983281          3.856942  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_pickle('KT_DCN/TFDS/dcn_reco_df.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 2.16 s, total: 5.61 s\n",
      "Wall time: 5.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reco_df = pd.read_pickle(\"KT_DCN/TFDS/dcn_reco_df.pickle\")   #size 195 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.532125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>3.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.160647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId             title  predicted_rating\n",
       "0      2       1  Toy Story (1995)          4.141455\n",
       "1      3       1  Toy Story (1995)          4.532125\n",
       "2      4       1  Toy Story (1995)          4.034204\n",
       "3      5       1  Toy Story (1995)          3.202344\n",
       "4      7       1  Toy Story (1995)          4.160647"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21384026</th>\n",
       "      <td>6036</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.472005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384027</th>\n",
       "      <td>6037</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.456575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384028</th>\n",
       "      <td>6038</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.716425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384029</th>\n",
       "      <td>6039</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.544908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384030</th>\n",
       "      <td>6040</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>2.920799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId movieId                  title  predicted_rating\n",
       "21384026   6036    3952  Contender, The (2000)          3.472005\n",
       "21384027   6037    3952  Contender, The (2000)          3.456575\n",
       "21384028   6038    3952  Contender, The (2000)          3.716425\n",
       "21384029   6039    3952  Contender, The (2000)          3.544908\n",
       "21384030   6040    3952  Contender, The (2000)          2.920799"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://betterprogramming.pub/load-fast-load-big-with-compressed-pickles-5f311584507e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle a file and then compress it into a file with extension \n",
    "def compressed_pickle(title, data):\n",
    "     with bz2.BZ2File(title + '.pbz2', 'w') as f:\n",
    "            cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    "     data = bz2.BZ2File(file, 'rb')\n",
    "     data = cPickle.load(data)\n",
    "     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('KT_DCN/TFDS/dcn_reco_df', df_copy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.3 s, sys: 1.9 s, total: 39.2 s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dcn_reco_df = decompress_pickle('KT_DCN/TFDS/dcn_reco_df.pbz2')  # Size 27.5MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.141455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.532125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>3.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>4.160647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserId movieId             title  predicted_rating\n",
       "0      2       1  Toy Story (1995)          4.141455\n",
       "1      3       1  Toy Story (1995)          4.532125\n",
       "2      4       1  Toy Story (1995)          4.034204\n",
       "3      5       1  Toy Story (1995)          3.202344\n",
       "4      7       1  Toy Story (1995)          4.160647"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_reco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21384026</th>\n",
       "      <td>6036</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.472005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384027</th>\n",
       "      <td>6037</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.456575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384028</th>\n",
       "      <td>6038</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.716425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384029</th>\n",
       "      <td>6039</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>3.544908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21384030</th>\n",
       "      <td>6040</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>2.920799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId movieId                  title  predicted_rating\n",
       "21384026   6036    3952  Contender, The (2000)          3.472005\n",
       "21384027   6037    3952  Contender, The (2000)          3.456575\n",
       "21384028   6038    3952  Contender, The (2000)          3.716425\n",
       "21384029   6039    3952  Contender, The (2000)          3.544908\n",
       "21384030   6040    3952  Contender, The (2000)          2.920799"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_reco_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the \"data\" with the \"title\" and adds the .pickle\n",
    "def full_pickle(title, data):\n",
    "    pikd = open(title + '.pickle', 'wb')\n",
    "    pickle.dump(data, pikd,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    pikd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads and returns a pickled objects\n",
    "def loosen(file):\n",
    "    pikd = open(file, 'rb')\n",
    "    data = pickle.load(pikd)\n",
    "    pikd.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pickle('KT_DCN/TFDS/dcn_reco_df_v2', df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 2.16 s, total: 5.67 s\n",
      "Wall time: 6.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dcn_reco_df_v2 = loosen('KT_DCN/TFDS/dcn_reco_df_v2.pickle')   # 195 MB size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict saving not needed (below cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_dict = df_copy.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'UserId': '1',\n",
       "  'movieId': '1',\n",
       "  'title': 'Toy Story (1995)',\n",
       "  'predicted_rating': 3.978767156600952},\n",
       " {'UserId': '2',\n",
       "  'movieId': '1',\n",
       "  'title': 'Toy Story (1995)',\n",
       "  'predicted_rating': 4.025431156158447},\n",
       " {'UserId': '3',\n",
       "  'movieId': '1',\n",
       "  'title': 'Toy Story (1995)',\n",
       "  'predicted_rating': 3.8028371334075928},\n",
       " {'UserId': '4',\n",
       "  'movieId': '1',\n",
       "  'title': 'Toy Story (1995)',\n",
       "  'predicted_rating': 4.488399982452393},\n",
       " {'UserId': '5',\n",
       "  'movieId': '1',\n",
       "  'title': 'Toy Story (1995)',\n",
       "  'predicted_rating': 3.694321632385254}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pickle('KT_DCN/TFDS/dcn_reco_dict_list', df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 983 ms, total: 4.46 s\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dcn_reco_dict = loosen('KT_DCN/TFDS/dcn_reco_dict_list.pickle')   # 224 MB size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 2.19 s, total: 6.23 s\n",
      "Wall time: 9.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_reco_df = pd.read_pickle(\"KT_DCN/TFDS/dcn_reco_df.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(userid,n):\n",
    "    reco_df = df_reco_df[df_reco_df['UserId']==str(userid)].sort_values(by='predicted_rating', ascending=False)[:n]\n",
    "    reco_df['score_normalized'] = (reco_df['predicted_rating']-min(reco_df['predicted_rating']))/(max(reco_df['predicted_rating'])-min(reco_df['predicted_rating']))\n",
    "    return_dict = {}\n",
    "    reco_list_dict = reco_df[['movieId','title']].to_dict(orient='records')\n",
    "    for i in range(n):\n",
    "        return_dict.update({i+1 : reco_list_dict[i]})\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dict = recommend(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'movieId': '2197', 'title': 'Firelight (1997)'}, 2: {'movieId': '3323', 'title': 'Chain of Fools (2000)'}, 3: {'movieId': '53', 'title': 'Lamerica (1994)'}, 4: {'movieId': '578', 'title': 'Hour of the Pig, The (1993)'}, 5: {'movieId': '668', 'title': 'Pather Panchali (1955)'}}\n"
     ]
    }
   ],
   "source": [
    "print(rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcn.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
